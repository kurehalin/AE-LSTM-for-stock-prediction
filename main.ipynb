{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_files = glob.glob(pathname='./data/legal/[0-9]*')\n",
    "feature_files=glob.glob(pathname='./data/feature/[0-9]*')\n",
    "\n",
    "covid_files=glob.glob(pathname='./data/COVID-19/*')\n",
    "\n",
    "df_1301 = pd.read_csv('./data/feature/1301_feature.csv',parse_dates=True,index_col='年月日')\n",
    "dfl_1301 = pd.read_csv('./data/legal/1301_legal.csv',parse_dates=True,index_col='年月日')\n",
    "df_1301.drop(['2021-11-24'],axis=0,inplace=True)\n",
    "\n",
    "covid_files=glob.glob(pathname='./data/COVID-19/*')\n",
    "cl = []\n",
    "for file in covid_files:\n",
    "    df = pd.read_csv(file,parse_dates=True,index_col='日期')\n",
    "    country = df['iso_code'][0]+'_'\n",
    "    df = df.add_prefix(country)\n",
    "    df = df.drop(columns=[country+'洲名',country+'國家',country+'ID',country+'iso_code'],axis=1)\n",
    "    cl.append(df)\n",
    "\n",
    "for i in range(len(cl)-1):\n",
    "    cl[i+1] = cl[i].join(cl[i+1])\n",
    "covid = cl[-1]\n",
    "covid = covid.drop(index=covid.loc['2021-11-24':].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 投信拉抬定義\n",
    "##### 投信買賣超/在外流通股數 = 投本比\n",
    "##### np.linspace(投本比min, 投本比max, 1000) = threshold產出(-1,0,1)的信號"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove string and comma in Dataframe\n",
    "# dfl_1301 = dfl_1301.drop(columns='簡稱',axis=1)\n",
    "def drop_name_comma(df,dfl):\n",
    "    '''丟掉證券名稱以及去除逗號'''\n",
    "    df.columns.name = dfl['證券名稱'].values[0] \n",
    "    dfl.columns.name = dfl['證券名稱'].values[0]\n",
    "    \n",
    "    try:\n",
    "        df = df.drop(columns='證券代碼')\n",
    "        dfl = dfl.drop(columns=['證券名稱','簡稱'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            df[col]=df[col].str.replace(',','')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return df,dfl\n",
    "df_1301,dfl_1301 = drop_name_comma(df_1301,dfl_1301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create needed columns\n",
    "# thresholds = np.linspace(dfl_1301['投本比%'].min(),dfl_1301['投本比%'].max(),1000)\n",
    "# Approach 1: -1,0,1\n",
    "# Approach 2: minmax scale(-1~1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def label_creator(dfl):\n",
    "    '''建立投本比%以及在外流通股數(千股)'''\n",
    "    '''signal_arr1為拉抬訊號-1,0,1; signal_arr2為拉抬訊號map between -1 and 1'''\n",
    "    \n",
    "    dfl['在外流通股數(千股)'] = dfl['投信持股數(千股)']/dfl['投信持股率%']\n",
    "    dfl['投本比%'] = (dfl['投信買賣超(千股)']/dfl['在外流通股數(千股)'])*100\n",
    "    signal_arr1 = []\n",
    "    for num in dfl['投本比%'].values:\n",
    "        if num >0:\n",
    "            signal_arr1.append(1)\n",
    "        elif num <0:\n",
    "            signal_arr1.append(-1)\n",
    "        else:\n",
    "            signal_arr1.append(0)\n",
    "    dfl['signal_arr1']=pd.Series(signal_arr1,index=dfl.index)\n",
    "\n",
    "    signal_arr2 = dfl['投本比%'].values.reshape(-1,1)\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    signal_arr2 = scaler.fit_transform(signal_arr2)\n",
    "    signal_arr2 = signal_arr2.reshape(2179,)\n",
    "    dfl['signal_arr2']=pd.Series(signal_arr2,index=dfl.index)\n",
    "\n",
    "    return dfl\n",
    "dfl_1301 = label_creator(dfl_1301)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "疫情爆發日為2020-01-22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_rolling(df:pd.DataFrame,dfl:pd.DataFrame)->np.array:\n",
    "    '''用疫情前資料每t天轉成一筆特徵，每t+5轉成一筆答案，t=60'''\n",
    "    b_data = []\n",
    "    b_signal = []\n",
    "    for i in range(len(df[:'2020-01-22'])-65):\n",
    "        b_data.append(df[:'2020-01-22'].iloc[i:60+i])\n",
    "        b_signal.append(dfl[:'2020-01-22'][['signal_arr1','signal_arr2']].iloc[[60+i+5]])\n",
    "    b_data = np.array(b_data).astype('float32')\n",
    "    b_signal = np.array(b_signal).astype('float32')\n",
    "    \n",
    "    return b_data , b_signal\n",
    "\n",
    "def after_rolling(df:pd.DataFrame,dfl:pd.DataFrame)->np.array:\n",
    "    '''用疫情後資料每t天轉成一筆特徵，每t+5轉成一筆答案，t=60'''\n",
    "    a_data = []\n",
    "    a_signal = []\n",
    "    for i in range(len(df['2020-01-22':])-65):\n",
    "        a_data.append(df['2020-01-22':].iloc[i:60+i])\n",
    "        a_signal.append(dfl['2020-01-22':][['signal_arr1','signal_arr2']].iloc[[60+i+5]])\n",
    "    a_data = np.array(a_data).astype('float32')\n",
    "    a_signal = np.array(a_signal).astype('float32')\n",
    "    \n",
    "    return a_data , a_signal\n",
    "\n",
    "def after_covid_rolling(df,covid):\n",
    "    '''原疫情後特徵+covid特徵'''\n",
    "    dfc = df.join(covid)\n",
    "    dfc = dfc.drop(index=dfc.loc[:'2020-01-24'].index)\n",
    "    c_data = []\n",
    "    for i in range(len(covid)-65):\n",
    "        c_data.append(dfc.iloc[i:60+i])\n",
    "    c_data =np.array(c_data).astype('float32')\n",
    "\n",
    "    return dfc,c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joyce\\AppData\\Local\\Temp/ipykernel_10712/3140939370.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  c_data =np.array(c_data).astype('float32')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'DataFrame'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10712/1294611258.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_signal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbefore_rolling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_1301\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdfl_1301\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ma_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma_signal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mafter_rolling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_1301\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdfl_1301\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdfc_1301\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mafter_covid_rolling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_1301\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcovid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10712/3140939370.py\u001b[0m in \u001b[0;36mafter_covid_rolling\u001b[1;34m(df, covid)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcovid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mc_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mc_data\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdfc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "#Train test split\n",
    "b_data,b_signal = before_rolling(df_1301,dfl_1301)\n",
    "a_data,a_signal = after_rolling(df_1301,dfl_1301)\n",
    "dfc_1301, c_data = after_covid_rolling(df_1301,covid)\n",
    "\n",
    "def train_test_split(data, signal):\n",
    "    '''Rolling完的資料7:3=訓練集:驗證集'''    \n",
    "    train_length= round(len(data)*0.7)\n",
    "\n",
    "    X_train,X_test,y_train,y_test = data[:train_length],data[train_length:],signal[:train_length],signal[train_length:]\n",
    "\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b,X_test_b,y_train_b,y_test_b = train_test_split(b_data,b_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq to seq LSTM\n",
    "timesteps = 60  # Length of your sequences\n",
    "input_dim = 24   # feature\n",
    "latent_dim = 1166  #\n",
    "\n",
    "inputs = keras.Input(shape=(timesteps, input_dim))\n",
    "encoded = keras.layers.LSTM(latent_dim)(inputs)\n",
    "\n",
    "decoded = keras.layers.RepeatVector(timesteps)(encoded)\n",
    "decoded = keras.layers.LSTM(input_dim, return_sequences=True)(decoded)\n",
    "\n",
    "sequence_autoencoder = keras.Model(inputs, decoded)\n",
    "encoder = keras.Model(inputs, encoded)\n",
    "sequence_autoencoder.compile(optimizer='adam',loss='mean_squared_error')\n",
    "sequence_autoencoder.fit(b_data,b_data,epochs=50,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - 8s 207ms/step - loss: 1410929262592.0000\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 1s 206ms/step - loss: 1410929262592.0000\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 1s 206ms/step - loss: 1410929131520.0000\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 1s 206ms/step - loss: 1410929131520.0000\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 1s 206ms/step - loss: 1410929131520.0000\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 1s 207ms/step - loss: 1410929131520.0000\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 1s 205ms/step - loss: 1410929131520.0000\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 1s 206ms/step - loss: 1410929131520.0000\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 1s 207ms/step - loss: 1410929131520.0000\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 1410929131520.0000\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 1s 207ms/step - loss: 1410929131520.0000\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 1s 208ms/step - loss: 1410929000448.0000\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 1s 203ms/step - loss: 1410928869376.0000\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 1s 212ms/step - loss: 1410929000448.0000\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 2s 212ms/step - loss: 1410929000448.0000\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 2s 221ms/step - loss: 1410929000448.0000\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 2s 217ms/step - loss: 1410929000448.0000\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 2s 217ms/step - loss: 1410928869376.0000\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 1s 211ms/step - loss: 1410929000448.0000\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 1s 211ms/step - loss: 1410929000448.0000\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 1s 208ms/step - loss: 1410929000448.0000\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 1s 206ms/step - loss: 1410929000448.0000\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 1s 208ms/step - loss: 1410929000448.0000\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 1s 206ms/step - loss: 1410929000448.0000\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 1s 206ms/step - loss: 1410929000448.0000\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 1s 205ms/step - loss: 1410929000448.0000\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 1s 205ms/step - loss: 1410929000448.0000\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 1410929000448.0000\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 1s 210ms/step - loss: 1410929000448.0000\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 1410928869376.0000\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 1s 207ms/step - loss: 1410929000448.0000\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 2s 216ms/step - loss: 1410929000448.0000\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 2s 228ms/step - loss: 1410929000448.0000\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 2s 221ms/step - loss: 1410929000448.0000\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 2s 221ms/step - loss: 1410929000448.0000\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 1410928869376.0000\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 1410929000448.0000\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 1410929000448.0000\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 1s 202ms/step - loss: 1410928869376.0000\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 2s 229ms/step - loss: 1410929000448.0000\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 2s 228ms/step - loss: 1410928869376.0000\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 2s 233ms/step - loss: 1410929000448.0000\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 2s 229ms/step - loss: 1410929000448.0000\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 2s 225ms/step - loss: 1410929000448.0000\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 2s 218ms/step - loss: 1410929000448.0000\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 1s 211ms/step - loss: 1410929000448.0000\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 1410929000448.0000\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 1410929000448.0000\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1410929000448.0000\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1410929000448.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15de08f4910>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.疫情前 + 疫情前 共1730筆資料(dfl_1301[:'2020-01-22'])\n",
    "from Autoencoder import Simple\n",
    "X_train_b,X_test_b,y_train_b,y_test_b = train_test_split(b_data,b_signal)\n",
    "Simple.encode()\n",
    "Simple.decode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1166"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.疫情前 + 疫情後 共2180筆資料(dfl_1301)\n",
    "X_train_b,X_test_b,y_train_a,y_test_a = b_data,b_signal,a_data,a_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.疫情後 + 疫情後 共450筆資料(df_1301['2020-01-22':])\n",
    "X_train_a,X_test_a,y_train_a,y_test_a = train_test_split(a_data,a_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.疫情後加covid feature + 疫情後\n",
    "X_train_c,X_test_c,y_train_a,y_test_a = train_test_split(c_data,a_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.不分疫情前後直接7:3 without covid feature predict"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8c14f33bbed64c468da1083d9a4ffa45baefb3d16ddb62461ae8fba926c479d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ML': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
